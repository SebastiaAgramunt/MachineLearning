{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X,Y,batch_size):\n",
    "    '''\n",
    "    Get batches of data, input is features,target\n",
    "    and batch_size, output is one minibatch\n",
    "    '''\n",
    "    iters = X.shape[0]//batch_size\n",
    "    for i in range(0,iters):\n",
    "        yield X[i*batch_size:(i+1)*batch_size],Y[i*batch_size:(i+1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "batch_size = 512\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "num_input = mnist.train.images.shape[1] # input = 28*28 = 784\n",
    "num_classes = mnist.train.labels.shape[1] # number of classes = 10\n",
    "dropout = 0.75 # Dropout probability\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes]) \n",
    "X_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv2d(input,n_input_channels,filter_size,n_filters,name = \"conv2d\",stride=1):\n",
    "    '''\n",
    "    Create a convolutional layer\n",
    "    Input:\n",
    "    =======\n",
    "        * input: The image or batch of images [-1,width,height,n_input_channels]\n",
    "        * n_input_channels: number of colours of our image\n",
    "        * filter_size: the size of the filter we want to apply\n",
    "        * n_filters: number of filters for this convolutional layer\n",
    "        * name: name of the scope\n",
    "        * stride of the window\n",
    "    Output:\n",
    "    =======\n",
    "        * The convolved layer and the weights (not including the bias)\n",
    "    '''\n",
    "    with tf.variable_scope(name):\n",
    "        shape = [filter_size, filter_size, n_input_channels, n_filters]\n",
    "\n",
    "        # Weights\n",
    "        W = tf.Variable(tf.truncated_normal(shape))\n",
    "\n",
    "        # Biases (one for each filter)\n",
    "        b = tf.Variable(tf.random_normal([n_filters]),name=\"b1\")\n",
    "\n",
    "        # Convolution using tensorflow function\n",
    "        layer = tf.nn.conv2d(input=input,\n",
    "                             filter=W,\n",
    "                             strides=[1, stride, stride, 1],\n",
    "                             padding='SAME')\n",
    "\n",
    "        # Add bias to the convolution\n",
    "        layer = tf.nn.bias_add(layer, b)\n",
    "\n",
    "        return layer\n",
    "    \n",
    "def new_pool(input, name,ksize = 2,stride = 2):\n",
    "    '''\n",
    "    Create a max-pool layer\n",
    "    Input:\n",
    "    ======\n",
    "        * input: the convolved layer\n",
    "        * name: name of the scope\n",
    "        * stride: stride of the window\n",
    "        * ksize: size of the window\n",
    "    '''\n",
    "    with tf.variable_scope(name):\n",
    "        # Operation for max pool, ksize indicate the size of the window to convovle\n",
    "        # and stride how we move such window\n",
    "        layer = tf.nn.max_pool(value=input,\n",
    "                               ksize=[1, ksize, ksize, 1],\n",
    "                               strides=[1, stride, stride, 1],\n",
    "                               padding='SAME')\n",
    "        \n",
    "        return layer\n",
    "\n",
    "def new_relu(input, name):\n",
    "    '''\n",
    "    Apply relu function\n",
    "    '''\n",
    "    with tf.variable_scope(name):\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.relu(input)\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "def new_fully_connected(input,flattened_size,n_nodes,name):\n",
    "    '''\n",
    "    Create new connected layer\n",
    "    Input:\n",
    "    ======\n",
    "        * input: the already flattened layer\n",
    "        * flattened_size: the size of the tensor when flatened\n",
    "        * n_nodes: number of new nodes\n",
    "        * name: name of the scope\n",
    "    '''\n",
    "    with tf.variable_scope(name):\n",
    "        #input is already flattened\n",
    "        shape = [flattened_size,n_nodes]\n",
    "        \n",
    "        # Weights\n",
    "        W = tf.Variable(tf.truncated_normal(shape))\n",
    "        #bias\n",
    "        b = tf.Variable(tf.truncated_normal([n_nodes]))\n",
    "\n",
    "        return tf.matmul(input, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I explain shapes assuming one sample at a time [1,28,28,1] instead of [N,28,28,1]\n",
    "#first layer X_image = tf.shape([1,28,28,1]) --> tf.shape(layer1) = [1,28,28,16]\n",
    "\n",
    "#Layer 1\n",
    "#======================================================\n",
    "layer1 = new_conv2d(X_image,\n",
    "                    n_input_channels =1,\n",
    "                    filter_size=5,\n",
    "                    n_filters = 16,\n",
    "                    name = \"layer1\")\n",
    "#This op preserves the shape\n",
    "layer1 = new_relu(layer1,\"layer1_relu\")\n",
    "# input is tf.shape() = [1,28,28,16] --> tf.shape() = [1,14,14,16]\n",
    "layer1 = new_pool(layer1, name = \"layer1_relu_pooling\")\n",
    "\n",
    "#Layer 2\n",
    "#======================================================\n",
    "#input is tf.shape() = [1,14,14,16] --> tf.shape() = [1,14,14,64]\n",
    "layer2 = new_conv2d(layer1,\n",
    "                    n_input_channels =16,\n",
    "                    filter_size=5,\n",
    "                    n_filters = 64,\n",
    "                    name = \"layer2\")\n",
    "#This op preserves the shape\n",
    "layer2 = new_relu(layer2,\"layer2_relu\")\n",
    "# input is tf.shape() = [1,14,14,64] --> tf.shape() = [1,7,7,64]\n",
    "layer2 = new_pool(layer2, name = \"layer2_relu_pooling\")\n",
    "# input is tf.shape() = [1,7,7,64] --> tf.shape() = [1,7*7*64]\n",
    "layer2 = tf.reshape(layer2,shape=[-1,7*7*64]) #-1 for all the rest\n",
    "\n",
    "#Layer 3\n",
    "#======================================================\n",
    "# input is tf.shape() = [1,7*7*64] --> [1,1024]\n",
    "layer3 = new_fully_connected(layer2,7*7*64,1024,\"fully_connected\")\n",
    "layer3 = new_relu(layer3,\"fully_connected_relu\")\n",
    "layer3 = tf.nn.dropout(layer3, dropout)\n",
    "\n",
    "#Output layer\n",
    "#======================================================\n",
    "output_layer = new_fully_connected(layer3,1024,10,\"output_layer\")\n",
    "#output_layer = tf.nn.softmax(output_layer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction from the output layer\n",
    "prediction = tf.nn.softmax(output_layer)\n",
    "\n",
    "# definition of loss and how to minimize\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=output_layer, labels=Y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "\n",
    "# metrics\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss= 1466.8944, accuracy= 0.850\n",
      "Epoch 1, loss= 626.4468, accuracy= 0.926\n",
      "Epoch 2, loss= 451.2798, accuracy= 0.936\n",
      "Epoch 3, loss= 228.2436, accuracy= 0.953\n",
      "Epoch 4, loss= 189.8061, accuracy= 0.953\n",
      "Epoch 5, loss= 179.8482, accuracy= 0.953\n",
      "Epoch 6, loss= 108.2457, accuracy= 0.959\n",
      "Epoch 7, loss= 67.3590, accuracy= 0.975\n",
      "Epoch 8, loss= 116.9878, accuracy= 0.963\n",
      "Epoch 9, loss= 67.6762, accuracy= 0.973\n",
      "Epoch 10, loss= 91.3225, accuracy= 0.971\n",
      "Epoch 11, loss= 97.9068, accuracy= 0.963\n",
      "Epoch 12, loss= 69.4139, accuracy= 0.973\n",
      "Epoch 13, loss= 65.2558, accuracy= 0.973\n",
      "Epoch 14, loss= 53.8750, accuracy= 0.967\n",
      "Testing Accuracy: 0.984375\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        data = get_batches(X=mnist.train.images,Y=mnist.train.labels,batch_size=batch_size)\n",
    "        #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        for x_,y_ in data:\n",
    "            sess.run(train_step,feed_dict = {X:x_,Y:y_,keep_prob: dropout})\n",
    "\n",
    "        if epoch % display_step == 0 or epoch == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: x_,\n",
    "                                                                 Y: y_,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            print(\"Epoch \" + str(epoch) + \", loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images[0:256],\n",
    "                                      Y: mnist.test.labels[0:256],\n",
    "                                      keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aind-dl]",
   "language": "python",
   "name": "conda-env-aind-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
