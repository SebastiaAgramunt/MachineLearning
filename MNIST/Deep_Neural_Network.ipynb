{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123c4e2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAEzCAYAAAAGisbbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nETHZAgAAiIjJFgAAQET/BxIpwS2oQAckAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123c4e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(2,3,figsize=(10,5))\n",
    "\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.imshow(mnist.train.images[i].reshape(28,28),cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(X,Y,batch_size):\n",
    "    '''\n",
    "    Get batches of data, input is features,target\n",
    "    and batch_size, output is one minibatch\n",
    "    '''\n",
    "    iters = X.shape[0]//batch_size\n",
    "    for i in range(0,iters):\n",
    "        yield X[i*batch_size:(i+1)*batch_size],Y[i*batch_size:(i+1)*batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with 3 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a nerual network with 3 hidden layers of 15 nodes each (exept the last one that has to be 10, the number of classes) that are fully connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.05 #learning rate, too big will cause NaNs.\n",
    "batch_size = 10 #size to input the model, max is mnist.train.images.shape[0], the full data\n",
    "epochs = 200 #number of epochs (times we pass trhough all the training data)\n",
    "display_step = 5 #every how many steps we display the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes_h1 = 15 #number of nodes first layer\n",
    "nodes_h2 = 15 #number of nodes second layer\n",
    "n_classes = 10 #classes\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, [None, 784],name=\"X\") #input \n",
    "    Y = tf.placeholder(tf.float32, [None, 10],name=\"Y\") #true classification\n",
    "\n",
    "with tf.name_scope('parameters'):\n",
    "    W_hidden_1 = tf.Variable(tf.random_normal([784,nodes_h1], name =\"W1\")) \n",
    "    b_hidden_1 = tf.Variable(tf.random_normal([nodes_h1]),name=\"b1\")\n",
    "\n",
    "    W_hidden_2 = tf.Variable(tf.random_normal([nodes_h1,nodes_h2], name =\"W2\"))\n",
    "    b_hidden_2 = tf.Variable(tf.random_normal([nodes_h2]),name=\"b2\")\n",
    "                             \n",
    "    W_output = tf.Variable(tf.random_normal([nodes_h2,n_classes]),name=\"W_output\")\n",
    "    b_output = tf.Variable(tf.random_normal([n_classes]),name=\"b_output\")\n",
    "                             \n",
    "layer_1 = tf.nn.softmax(tf.matmul(X, W_hidden_1) + b_hidden_1)\n",
    "layer_2 = tf.nn.softmax(tf.matmul(layer_1, W_hidden_2) + b_hidden_2)\n",
    "\n",
    "with tf.name_scope('prediction'):\n",
    "    y = tf.nn.softmax(tf.matmul(layer_2, W_output) + b_output)\n",
    "\n",
    "#the error to minimize is the cross_entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#train the nn with simple gradient descent\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "#saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#to show in tensorboard\n",
    "summary_acc = tf.summary.scalar(name=\"acc\",tensor=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy:0.35530000925064087, cross_entropy:1.6375553607940674\n",
      "epoch: 5, accuracy:0.5597000122070312, cross_entropy:1.0829017162322998\n",
      "epoch: 10, accuracy:0.7307000160217285, cross_entropy:0.7259600758552551\n",
      "epoch: 15, accuracy:0.7524999976158142, cross_entropy:0.6786924004554749\n",
      "epoch: 20, accuracy:0.7712000012397766, cross_entropy:0.6719315648078918\n",
      "epoch: 25, accuracy:0.7906000018119812, cross_entropy:0.6145690679550171\n",
      "epoch: 30, accuracy:0.798799991607666, cross_entropy:0.5906968712806702\n",
      "epoch: 35, accuracy:0.7978000044822693, cross_entropy:0.5883212685585022\n",
      "epoch: 40, accuracy:0.7979999780654907, cross_entropy:0.5889756679534912\n",
      "epoch: 45, accuracy:0.7950000166893005, cross_entropy:0.5999442338943481\n",
      "epoch: 50, accuracy:0.7929999828338623, cross_entropy:0.6034144163131714\n",
      "epoch: 55, accuracy:0.7964000105857849, cross_entropy:0.5988724827766418\n",
      "epoch: 60, accuracy:0.7964000105857849, cross_entropy:0.6042076349258423\n",
      "epoch: 65, accuracy:0.8048999905586243, cross_entropy:0.5869981050491333\n",
      "epoch: 70, accuracy:0.8116999864578247, cross_entropy:0.571016788482666\n",
      "epoch: 75, accuracy:0.8149999976158142, cross_entropy:0.5683572888374329\n",
      "epoch: 80, accuracy:0.8109999895095825, cross_entropy:0.5828119516372681\n",
      "epoch: 85, accuracy:0.8195000290870667, cross_entropy:0.5606711506843567\n",
      "epoch: 90, accuracy:0.8402000069618225, cross_entropy:0.5283377170562744\n",
      "epoch: 95, accuracy:0.8687000274658203, cross_entropy:0.4933849573135376\n",
      "epoch: 100, accuracy:0.9014999866485596, cross_entropy:0.43259379267692566\n",
      "epoch: 105, accuracy:0.901199996471405, cross_entropy:0.4274751842021942\n",
      "epoch: 110, accuracy:0.9013000130653381, cross_entropy:0.42741143703460693\n",
      "epoch: 115, accuracy:0.9057000279426575, cross_entropy:0.4097890555858612\n",
      "epoch: 120, accuracy:0.9071999788284302, cross_entropy:0.40716996788978577\n",
      "epoch: 125, accuracy:0.9090999960899353, cross_entropy:0.4020511209964752\n",
      "epoch: 130, accuracy:0.9128000140190125, cross_entropy:0.38902410864830017\n",
      "epoch: 135, accuracy:0.9125999808311462, cross_entropy:0.3893996477127075\n",
      "epoch: 140, accuracy:0.9164999723434448, cross_entropy:0.38117679953575134\n",
      "epoch: 145, accuracy:0.9128000140190125, cross_entropy:0.39871904253959656\n",
      "epoch: 150, accuracy:0.9118000268936157, cross_entropy:0.4014515280723572\n",
      "epoch: 155, accuracy:0.9118000268936157, cross_entropy:0.39948010444641113\n",
      "epoch: 160, accuracy:0.9150000214576721, cross_entropy:0.390582799911499\n",
      "epoch: 165, accuracy:0.9129999876022339, cross_entropy:0.40354129672050476\n",
      "epoch: 170, accuracy:0.9107999801635742, cross_entropy:0.4064912796020508\n",
      "epoch: 175, accuracy:0.9110000133514404, cross_entropy:0.4079133868217468\n",
      "epoch: 180, accuracy:0.9111999869346619, cross_entropy:0.40922048687934875\n",
      "epoch: 185, accuracy:0.9150999784469604, cross_entropy:0.3932216763496399\n",
      "epoch: 190, accuracy:0.9125000238418579, cross_entropy:0.40526387095451355\n",
      "epoch: 195, accuracy:0.9097999930381775, cross_entropy:0.41473907232284546\n",
      "Model saved in path: ./tmp/neural_network_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(\"./tmp\", graph=sess.graph)\n",
    "    for epoch in range(epochs):\n",
    "        data = get_batches(X=mnist.train.images,Y=mnist.train.labels,batch_size=batch_size)\n",
    "        for x_,y_ in data:\n",
    "            sess.run(train_step,feed_dict = {X:x_,Y:y_})\n",
    "        \n",
    "        if epoch % display_step == 0:\n",
    "            print(\"epoch: {}, accuracy:{}, cross_entropy:{}\".format(epoch,\n",
    "                sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels}),\n",
    "                sess.run(cross_entropy,feed_dict = {X:mnist.test.images,Y:mnist.test.labels})))\n",
    "            \n",
    "        summary = sess.run(summary_acc,feed_dict={Y : mnist.train.labels,X : mnist.train.images})\n",
    "        writer.add_summary(summary, epoch)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./tmp/neural_network_model.ckpt\")\n",
    "    print(\"Model saved in path: {}\".format(save_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net of 2 layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural net achieved an error of 1.6 according to [this article](https://en.wikipedia.org/wiki/MNIST_database). 2-layer 784-800-10. But here we need a lot of steps to train and get this small error, we will not run so many epochs. Besides this structure has more parameters (800 actually) than the nn of 3 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.05 #learning rate, too big will cause NaNs.\n",
    "batch_size = 10 #size to input the model, max is mnist.train.images.shape[0], the full data\n",
    "epochs = 200 #number of epochs (times we pass trhough all the training data)\n",
    "display_step = 5 #every how many steps we display the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_h1 = 800 #number of nodes first layer\n",
    "n_classes = 10 #classes\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, [None, 784],name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 10],name=\"Y\")\n",
    "\n",
    "with tf.name_scope('parameters'):\n",
    "    W_hidden_1 = tf.Variable(tf.random_normal([784,nodes_h1], name =\"W1\"))\n",
    "    b_hidden_1 = tf.Variable(tf.random_normal([nodes_h1]),name=\"b1\")\n",
    "                          \n",
    "    W_output = tf.Variable(tf.random_normal([nodes_h1,n_classes]),name=\"W_output\")\n",
    "    b_output = tf.Variable(tf.random_normal([n_classes]),name=\"b_output\")\n",
    "                             \n",
    "layer_1 = tf.nn.softmax(tf.matmul(X, W_hidden_1) + b_hidden_1)\n",
    "\n",
    "with tf.name_scope('prediction'):\n",
    "    y = tf.nn.softmax(tf.matmul(layer_1, W_output) + b_output)\n",
    "    \n",
    "#the error to minimize is the cross_entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#train the nn with simple gradient descent\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "#saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#to show in tensorboard\n",
    "summary_acc = tf.summary.scalar(name=\"acc\",tensor=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy:0.572700023651123, cross_entropy:1.1352640390396118\n",
      "epoch: 5, accuracy:0.8169000148773193, cross_entropy:0.5566388964653015\n",
      "epoch: 10, accuracy:0.8356999754905701, cross_entropy:0.4961489140987396\n",
      "epoch: 15, accuracy:0.847100019454956, cross_entropy:0.4736345708370209\n",
      "epoch: 20, accuracy:0.8758999705314636, cross_entropy:0.43066534399986267\n",
      "epoch: 25, accuracy:0.8736000061035156, cross_entropy:0.42929980158805847\n",
      "epoch: 30, accuracy:0.8772000074386597, cross_entropy:0.4220755398273468\n",
      "epoch: 35, accuracy:0.8758999705314636, cross_entropy:0.42586392164230347\n",
      "epoch: 40, accuracy:0.8787000179290771, cross_entropy:0.42259687185287476\n",
      "epoch: 45, accuracy:0.8797000050544739, cross_entropy:0.42229726910591125\n",
      "epoch: 50, accuracy:0.8837000131607056, cross_entropy:0.4152168035507202\n",
      "epoch: 55, accuracy:0.8881999850273132, cross_entropy:0.40752679109573364\n",
      "epoch: 60, accuracy:0.8884999752044678, cross_entropy:0.4076586365699768\n",
      "epoch: 65, accuracy:0.8895000219345093, cross_entropy:0.40398696064949036\n",
      "epoch: 70, accuracy:0.890999972820282, cross_entropy:0.401689738035202\n",
      "epoch: 75, accuracy:0.890999972820282, cross_entropy:0.4009884297847748\n",
      "epoch: 80, accuracy:0.8894000053405762, cross_entropy:0.40520212054252625\n",
      "epoch: 85, accuracy:0.8921999931335449, cross_entropy:0.4031235873699188\n",
      "epoch: 90, accuracy:0.892799973487854, cross_entropy:0.4025716185569763\n",
      "epoch: 95, accuracy:0.8938000202178955, cross_entropy:0.39979633688926697\n",
      "epoch: 100, accuracy:0.8939999938011169, cross_entropy:0.4000464975833893\n",
      "epoch: 105, accuracy:0.8937000036239624, cross_entropy:0.3985957205295563\n",
      "epoch: 110, accuracy:0.8938999772071838, cross_entropy:0.39727655053138733\n",
      "epoch: 115, accuracy:0.8938999772071838, cross_entropy:0.3988342583179474\n",
      "epoch: 120, accuracy:0.8928999900817871, cross_entropy:0.4014117419719696\n",
      "epoch: 125, accuracy:0.8921999931335449, cross_entropy:0.40332794189453125\n",
      "epoch: 130, accuracy:0.8910999894142151, cross_entropy:0.4043622612953186\n",
      "epoch: 135, accuracy:0.8938999772071838, cross_entropy:0.4009633958339691\n",
      "epoch: 140, accuracy:0.8938999772071838, cross_entropy:0.4002131223678589\n",
      "epoch: 145, accuracy:0.8970999717712402, cross_entropy:0.3934243619441986\n",
      "epoch: 150, accuracy:0.9003000259399414, cross_entropy:0.3856823146343231\n",
      "epoch: 155, accuracy:0.9034000039100647, cross_entropy:0.3791799247264862\n",
      "epoch: 160, accuracy:0.9072999954223633, cross_entropy:0.37306737899780273\n",
      "epoch: 165, accuracy:0.9101999998092651, cross_entropy:0.3669447600841522\n",
      "epoch: 170, accuracy:0.9150999784469604, cross_entropy:0.3558977544307709\n",
      "epoch: 175, accuracy:0.9217000007629395, cross_entropy:0.34092774987220764\n",
      "epoch: 180, accuracy:0.9236000180244446, cross_entropy:0.33324018120765686\n",
      "epoch: 185, accuracy:0.9259999990463257, cross_entropy:0.326917439699173\n",
      "epoch: 190, accuracy:0.9273999929428101, cross_entropy:0.32487979531288147\n",
      "epoch: 195, accuracy:0.9271000027656555, cross_entropy:0.3265869617462158\n",
      "Model saved in path: ./tmp/neural_network_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(\"./tmp\", graph=sess.graph)\n",
    "    for epoch in range(epochs):\n",
    "        data = get_batches(X=mnist.train.images,Y=mnist.train.labels,batch_size=batch_size)\n",
    "        for x_,y_ in data:\n",
    "            sess.run(train_step,feed_dict = {X:x_,Y:y_})\n",
    "        \n",
    "        if epoch % display_step == 0:\n",
    "            print(\"epoch: {}, accuracy:{}, cross_entropy:{}\".format(epoch,\n",
    "                sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels}),\n",
    "                sess.run(cross_entropy,feed_dict = {X:mnist.test.images,Y:mnist.test.labels})))\n",
    "            \n",
    "        summary = sess.run(summary_acc,feed_dict={Y : mnist.train.labels,X : mnist.train.images})\n",
    "        writer.add_summary(summary, epoch)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./tmp/neural_network_model.ckpt\")\n",
    "    print(\"Model saved in path: {}\".format(save_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
